<template>
  <div class="call-container" :class="{ 'video-call': isVideoCall }">
    <!-- Arri√®re-plan avec initiale pour l'appelant et l'appel√© -->
    <div
      class="background-initial"
      v-if="
        !isVideoCall && (callStatus === 'outgoing' || callStatus === 'incoming')
      "
    >
      <span class="large-initial">
        {{
          callStatus === "outgoing"
            ? remoteUserId.charAt(0).toUpperCase()
            : currentUserId.charAt(0).toUpperCase()
        }}
      </span>
    </div>
    <!-- chrono pour indiquer la dur√©e d'appel (√† commencer du moment o√π l'appel a commenc√©)-->
    <div class="call-timer mt-3" v-if="currentCallStatus === 'connected'">
      {{ formattedCallDuration }}
    </div>

    <!-- Indicateur du statut d'appel -->
    <div class="call-status">
      <div class="status-message text-center mt-5">
        <template v-if="currentCallStatus === 'outgoing'">
          Appel en cours avec {{ remoteUserId }}...
        </template>
        <template v-else-if="currentCallStatus === 'incoming'">
          Appel entrant de {{ remoteUserId }}...
        </template>
        <template v-else-if="currentCallStatus === 'connected'">
          En appel avec {{ remoteUserId }}
        </template>
      </div>
    </div>
    <!-- Affichage du flux audio/vid√©o -->
    <div class="remote-stream-container relative">
      <video
        v-if="remoteStream"
        id="remoteVideo"
        autoplay
        playsinline
        :muted="false"
        :volume="1.0"
        :style="{ transform: 'scaleX(-1)' }"
        style="width: 100%; height: 100%; object-fit: cover"
      ></video>

      <!-- Bouton de lecture de secours -->
      <button
        v-if="showPlayButton && remoteStream"
        @click="forcePlayRemoteVideo"
        class="play-video-button"
      >
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          fill="currentColor"
          class="w-12 h-12"
        >
          <path d="M8 5v14l11-7z" />
        </svg>
        <span>Cliquez pour d√©marrer la vid√©o</span>
      </button>

      <div class="remote-audio-indicator" v-if="!isVideoCall">
        <div class="user-avatar">
          <span
            class="text-2xl font-bold text-indigo-600 dark:text-indigo-300 bg-white dark:bg-gray-800 rounded-full w-28 h-28 flex items-center justify-center"
          >
            {{ remoteUserId.charAt(0).toUpperCase() }}
          </span>
        </div>
        <div class="audio-waves">
          <span></span>
          <span></span>
          <span></span>
          <span></span>
        </div>
      </div>

      <div class="absolute top-4 right-4 z-20" v-if="userRole === 'agent'">
        <button @click="toggleRecording"
        :disabled="awaitingRecordPermission"
          :class="[
            isRecording ? 'bg-orange-500 hover:bg-orange-600' : 'bg-green-500 hover:bg-green-600',
            awaitingRecordPermission ? 'opacity-50 cursor-not-allowed' : ''
          ]"
          class="text-white p-2 rounded-full shadow-lg" title="Enregistrer l'appel">
          <svg v-if="awaitingRecordPermission" class="animate-spin h-6 w-6 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
          </svg>

           <svg v-else-if="!isRecording" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none"
            viewBox="0 0 24 24" stroke="currentColor">
            <circle cx="12" cy="12" r="10" stroke-width="2" />
            <circle cx="12" cy="12" r="4" fill="currentColor" />
          </svg>

          <svg v-else xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24"
            stroke="currentColor">
            <rect x="9" y="9" width="6" height="6" fill="currentColor" stroke-width="2" />
            <circle cx="12" cy="12" r="10" stroke-width="2" />
          </svg>
        </button>
      </div>
    </div>

    <!-- flux de partage d'√©cran -->
    <video
      v-if="screenSharingActive && !isScreenSharer"
      ref="screenShareVideo"
      :key="'screen-' + Date.now()"
      autoplay
      playsinline
      class="screen-share-video"
    ></video>
    <!-- Affichage du flux de la vid√©o localement -->
    <div
      class="local-stream-container"
      v-if="currentCallStatus === 'connected' || localStream"
    >
        <!-- Pour le client... -->
      <video
        ref="localVideo"
        autoplay
        muted
        :class="{ hidden: !isVideoCall }"
        :style="{ transform: 'scaleX(-1)' }"
      ></video>
      <div class="local-audio-indicator" v-if="!isVideoCall">
        <div class="user-avatar">
          <span
            class="text-xl font-bold text-indigo-600 dark:text-indigo-300 bg-white dark:bg-gray-800 rounded-full w-16 h-16 flex items-center justify-center"
          >
            {{ currentUserId.charAt(0).toUpperCase() }}
          </span>
        </div>
      </div>
    </div>

    <div class="remote-media-indicators space-y-3 fixed top-5 right-5 z-50">
      <transition
        enter-active-class="transform ease-out duration-300 transition"
        enter-from-class="translate-y-[-20px] opacity-0"
        enter-to-class="translate-y-0 opacity-100"
        leave-active-class="transform ease-in duration-200 transition"
        leave-from-class="translate-y-0 opacity-100"
        leave-to-class="translate-y-[-20px] opacity-0"
      >
        <div
          v-if="!remoteVideoEnabled"
          class="video-disabled-indicator flex items-center bg-gradient-to-r from-red-500 to-red-600 text-white px-5 py-3 rounded-lg shadow-xl backdrop-blur-sm border border-red-400"
        >
          <div class="flex items-center space-x-3">
            <div class="p-2 bg-red-700 rounded-full">
              <span class="text-xl">üé•</span>
            </div>
            <div>
              <p class="text-sm font-medium">Cam√©ra d√©sactiv√©e</p>
              <p class="text-xs opacity-80">
                {{ remoteUserId }} a coup√© sa cam√©ra
              </p>
            </div>
          </div>
        </div>
      </transition>

      <transition
        enter-active-class="transform ease-out duration-300 transition"
        enter-from-class="translate-y-[-20px] opacity-0"
        enter-to-class="translate-y-0 opacity-100"
        leave-active-class="transform ease-in duration-200 transition"
        leave-from-class="translate-y-0 opacity-100"
        leave-to-class="translate-y-[-20px] opacity-0"
      >
        <div
          v-if="!remoteAudioEnabled"
          class="audio-disabled-indicator flex items-center bg-gradient-to-r from-gray-700 to-gray-800 text-white px-5 py-3 rounded-lg shadow-xl backdrop-blur-sm border border-gray-600"
        >
          <div class="flex items-center space-x-3">
            <div class="p-2 bg-gray-900 rounded-full">
              <span class="text-xl">üé§</span>
            </div>
            <div>
              <p class="text-sm font-medium">Micro d√©sactiv√©</p>
              <p class="text-xs opacity-80">
                {{ remoteUserId }} a coup√© son micro
              </p>
            </div>
          </div>
        </div>
      </transition>
    </div>

    <!-- Commandes d'appel -->
    <div class="call-controls">
      <!-- couper le son de l'appel -->
      <button
        @click="toggleMute"
        class="control-btn"
        :class="{ active: isMuted }"
      >
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          fill="currentColor"
          class="w-6 h-6"
        >
          <path
            v-if="!isMuted"
            d="M8.25 4.5a3.75 3.75 0 117.5 0v8.25a3.75 3.75 0 11-7.5 0V4.5z"
          />
          <path
            v-if="!isMuted"
            d="M6 10.5a.75.75 0 01.75.75v1.5a5.25 5.25 0 1010.5 0v-1.5a.75.75 0 011.5 0v1.5a6.751 6.751 0 01-6 6.709v2.291h3a.75.75 0 010 1.5h-7.5a.75.75 0 010-1.5h3v-2.291a6.751 6.751 0 01-6-6.709v-1.5A.75.75 0 016 10.5z"
          />
          <path
            v-if="isMuted"
            d="M10.5 1.875a1.125 1.125 0 012.25 0v8.25c0 .621-.504 1.125-1.125 1.125h-1.5a1.125 1.125 0 01-1.125-1.125v-8.25a1.125 1.125 0 011.125-1.125h1.5zm-4.5 4.5a.75.75 0 00-1.5 0v5.25c0 2.9 2.35 5.25 5.25 5.25h3a.75.75 0 000-1.5h-3a3.75 3.75 0 01-3.75-3.75V6.375z"
          />
          <path
            v-if="isMuted"
            d="M19.78 17.28a.75.75 0 00-1.06-1.06L6.22 28.72a.75.75 0 101.06 1.06L19.78 17.28z"
          />
        </svg>
      </button>
      <!-- basculer entre l'affichage et le masquage de la vid√©o -->
      <button
        @click="toggleVideo"
        class="control-btn"
        :class="{ active: isVideoOff }"
        v-if="isVideoCall"
      >
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          fill="currentColor"
          class="w-6 h-6"
        >
          <path
            v-if="!isVideoOff"
            d="M4.5 4.5a3 3 0 00-3 3v9a3 3 0 003 3h8.25a3 3 0 003-3v-9a3 3 0 00-3-3H4.5zM19.94 18.75l-2.69-2.69V7.94l2.69-2.69c.944-.945 2.56-.276 2.56 1.06v11.38c0 1.336-1.616 2.005-2.56 1.06z"
          />
          <path
            v-if="isVideoOff"
            d="M3.53 2.47a.75.75 0 00-1.06 1.06l18 18a.75.75 0 101.06-1.06l-18-18zM22.5 17.69c0 .471-.202.86-.504 1.124l-9.309-9.31c.043-.043.086-.084.129-.124H21a1.5 1.5 0 011.5 1.5v6.75z"
          />
        </svg>
      </button>
      <!-- partager l'√©cran -->
      <button
        @click="startScreenShare"
        class="control-btn"
        v-if="currentCallStatus === 'connected' && userRole !== 'agent'"
      >
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          fill="currentColor"
          class="w-6 h-6"
        >
          <path
            d="M4 4h16a2 2 0 012 2v12a2 2 0 01-2 2H4a2 2 0 01-2-2V6a2 2 0 012-2zm0 2v12h16V6H4zm8 3l4 4h-3v4h-2v-4H8l4-4z"
          />
        </svg>
      </button>
      <!-- mettre fin √† l'appel -->
      <button @click="endCall" class="control-btn end-call">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24">
          <path fill="currentColor" d="m3.68 16.07l3.92-3.11V9.59c2.85-.93 5.94-.93 8.8 0v3.38l3.91 3.1L24 12.39c-6.41-7.19-17.59-7.19-24 0z"/>
        </svg>
      </button>
    </div>

    <!-- Commandes d'appel entrant -->
    <div class="incoming-call-controls" v-if="callStatus === 'incoming'">
      <!-- accepter l'appel -->
      <button @click="acceptCall()" class="accept-btn">
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          fill="currentColor"
          class="w-6 h-6"
        >
          <path
            fill-rule="evenodd"
            d="M1.5 4.5a3 3 0 013-3h1.372c.86 0 1.61.586 1.819 1.42l1.105 4.423a1.875 1.875 0 01-.694 1.955l-1.293.97c-.135.101-.164.249-.126.352a11.285 11.285 0 006.697 6.697c.103.038.25.009.352-.126l.97-1.293a1.875 1.875 0 011.955-.694l4.423 1.105c.834.209 1.42.959 1.42 1.82V19.5a3 3 0 01-3 3h-2.25C8.552 22.5 1.5 15.448 1.5 6.75V4.5z"
            clip-rule="evenodd"
          />
        </svg>
        Accepter
      </button>
      <!-- rejeter l'appel -->
      <button @click="rejectCall" class="reject-btn">
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          fill="currentColor"
          class="w-6 h-6"
        >
          <path
            fill-rule="evenodd"
            d="M1.5 4.5a3 3 0 013-3h1.372c.86 0 1.61.586 1.819 1.42l1.105 4.423a1.875 1.875 0 01-.694 1.955l-1.293.97c-.135.101-.164.249-.126.352a11.285 11.285 0 006.697 6.697c.103.038.25.009.352-.126l.97-1.293a1.875 1.875 0 011.955-.694l4.423 1.105c.834.209 1.42.959 1.42 1.82V19.5a3 3 0 01-3 3h-2.25C8.552 22.5 1.5 15.448 1.5 6.75V4.5z"
            clip-rule="evenodd"
          />
          <path
            fill-rule="evenodd"
            d="M3.53 2.47a.75.75 0 00-1.06 1.06l18 18a.75.75 0 101.06-1.06l-18-18z"
            clip-rule="evenodd"
          />
        </svg>
        Rejeter
      </button>
    </div>
  </div>
</template>

<script setup>
import { ref, onMounted, onUnmounted, watch, computed, nextTick } from "vue";
import WebRTCService from "../services/WebRTCService";
import { useToast } from "vue-toastification";
import Peer from "peerjs";

const iceCandidateReceived = ref(false);
/**
 * transfert de flux d'audio ou vid√©o
 *
 */
// propri√©t√©s √† recevoir
const props = defineProps({
  socket: Object,
  currentUserId: String,
  remoteUserId: String,
  isVideoCall: Boolean,
  callStatus: String,
  isIncoming: Boolean,
  userRole: String,
  initialLocalStream: MediaStream,
});

const peerConnection = ref(null);
const remotePeerConnection = ref(null);
const screenSharingActive = ref(false);
const screenShareVideo = ref(null);
const awaitingRecordPermission = ref(false);

// √©v√©nements √† √©mettre
const emit = defineEmits([
  "call-ended",
  "call-status-change",
  "video-disabled",
]);

// notification(s)
const toast = useToast();

// R√©f√©rences pour les √©l√©ments vid√©os
const localVideo = ref(null);
const remoteVideo = ref(null);
const isRecording = ref(false);

// Variables d'√©tat
const localStream = ref(null);
const remoteStream = ref(null);
const isMuted = ref(false);
const isVideoOff = ref(false);

// cr√©ation d'une r√©f√©rence locale pour l'√©tat de la vid√©o
const localIsVideoCall = ref(props.isVideoCall);
const currentCallStatus = ref("");

// Utiliser la prop initialLocalStream pour l'aper√ßu local.
// Ce watcher s'assure que localStream.value est mis √† jour si la prop arrive ou change.
watch(() => props.initialLocalStream, (newStream) => {
  if (newStream) {
    localStream.value = newStream;
  }
}, { immediate: true }); // immediate: true pour l'initialisation au montage si la prop est d√©j√† l√†.

// Suivre les changements du flux de la vid√©o (afficher en temps r√©el ce que transmet la cam√©ra de l'appelant)
watch(
  () => props.isVideoCall,
  (newValue) => {
    localIsVideoCall.value = newValue;
  }
);

const callStatusText = computed(() => {
  switch (currentCallStatus.value) {
    case "outgoing":
      return "Appel en cours";
    case "incoming":
      return "Appel entrant";
    case "connected":
      return "Appel connect√©";
    default:
      return "En attente";
  }
});

const toggleRecording = () => {
  if (isRecording.value) { // Si on enregistre d√©j√†, on arr√™te
    if (WebRTCService.stopRecording()) {
      isRecording.value = false;
      props.socket.emit('recording-status-changed', { to: props.remoteUserId, recording: false });
      toast.info("Enregistrement arr√™t√©.");
    } else {
      toast.error("Erreur lors de l'arr√™t de l'enregistrement.");
    }
  // if (!isRecording.value) {
  //   if (WebRTCService.startRecording()) {
  //     isRecording.value = true;
  //   }
  // } else {
  //   if (WebRTCService.stopRecording()) {
  //     isRecording.value = false;
  //   }
  } else { // Sinon, on demande la permission pour d√©marrer
    if (awaitingRecordPermission.value) return; // D√©j√† en attente d'une r√©ponse

    awaitingRecordPermission.value = true;
    props.socket.emit('request-record-permission', {
      from: props.currentUserId, // ID de l'agent
      to: props.remoteUserId    // ID du client
    });
    toast.info("Demande d'autorisation d'enregistrement envoy√©e au client...");
  }
};

const callStartTime = ref(null);
const callDuration = ref(0);
const timerInterval = ref(null);
const isCallBeingRecordedByAgent = ref(false);

// Ajoutez cette computed property pour formater la dur√©e
const formattedCallDuration = computed(() => {
  const minutes = Math.floor(callDuration.value / 60);
  const seconds = callDuration.value % 60;
  return `${minutes.toString().padStart(2, "0")}:${seconds
    .toString()
    .padStart(2, "0")}`;
});

/**
 *  d√©marrage d'un appel vid√©o ou audio sortant, en v√©rifiant la disponibilit√© des p√©riph√©riques
 * et en ajustant l'appel en fonction des ressources disponibles (cam√©ra et micro).
 */
const startOutgoingCall = async () => {
  try {
    // Demander √† WebRTCService de r√©cup√©rer les flux audio/vid√©o locaux en fonction du type d'appel
    const result = await WebRTCService.getLocalMedia(localIsVideoCall.value);

    // V√©rifier si la r√©cup√©ration du flux a √©chou√©
    if (!result.success) {
      // Si aucun p√©riph√©rique audio n'est trouv√©, afficher un avertissement et terminer l'appel
      if (result.noAudioDevice) {
        toast.warning(
          "Aucun p√©riph√©rique audio trouv√©. Impossible de passer un appel."
        );
        emit("call-ended"); // √âmettre un √©v√©nement pour signaler que l'appel est termin√©
        return;
      }
      // Si une autre erreur se produit, lever une exception
      throw result.error;
    }

    // Si la cam√©ra n'est pas disponible, proposer de passer √† un appel audio
    if (result.fallbackToAudio) {
      const switchToAudio = confirm(
        "Aucune cam√©ra n'a √©t√© trouv√©e. Voulez-vous basculer vers un appel audio ?"
      );
      // Si l'utilisateur accepte, passer en mode appel audio
      if (switchToAudio) {
        localIsVideoCall.value = false; // Mettre √† jour le type d'appel √† audio
        emit("video-disabled"); // √âmettre un √©v√©nement pour indiquer que la vid√©o est d√©sactiv√©e
      } else {
        emit("call-ended"); // Sinon, terminer l'appel
        return;
      }
    }

    // Si tout est bon, initialiser le flux local et d√©finir l'√©tat de l'appel comme sortant
    localStream.value = result.stream;
    currentCallStatus.value = "outgoing"; // Mettre √† jour l'√©tat de l'appel en cours √† 'sortant'

    // Appeler la fonction pour √©tablir l'appel avec l'utilisateur distant
    await WebRTCService.makeCall(
      props.remoteUserId,
      !result.fallbackToAudio && localIsVideoCall.value
    );

    // Mettre √† jour le statut apr√®s que l'appel est √©tabli
    currentCallStatus.value = "connected";
    emit(
      "call-status-change",
      "connected",
      props.remoteUserId,
      localIsVideoCall.value
    );
  } catch (error) {
    // En cas d'erreur lors de l'initialisation de l'appel, afficher un message d'erreur
    console.error("Failed to start call:", error);
    toast.error(
      "Erreur lors de l'initialisation de l'appel. Veuillez r√©essayer."
    );
    emit("call-ended"); // √âmettre un √©v√©nement pour signaler que l'appel est termin√©
  }
};

const showPlayButton = ref(false);

// Ajoutez cette m√©thode pour forcer la lecture
const forcePlayRemoteVideo = () => {
  const remoteVideo = document.getElementById("remoteVideo");
  if (remoteVideo && remoteStream.value) {

    // R√©initialiser le srcObject pour √©viter les probl√®mes
    const currentStream = remoteVideo.srcObject;
    remoteVideo.srcObject = null;

    // Petit d√©lai avant de r√©attacher le flux
    setTimeout(() => {
      remoteVideo.srcObject = currentStream;
      remoteVideo.volume = 1.0;
      remoteVideo.muted = false;

      remoteVideo
        .play()
        .then(() => {
          showPlayButton.value = false;
        })
        .catch((error) => {
          console.error("√âchec de la lecture forc√©e:", error);
        });
    }, 100);
  }
};

/**
 *  g√®re le flux vid√©o/audio distant re√ßu.
 *  met √† jour le flux distant et l'affiche si un √©l√©ment vid√©o est pr√©sent.
 * @param {MediaStream} stream - Le flux vid√©o/audio distant √† afficher.
 */
const handleRemoteStream = (stream) => {
  remoteStream.value = stream;

  // Utiliser une approche plus robuste pour attacher le flux √† l'√©l√©ment vid√©o
  const attachStreamToVideo = () => {
    const remoteVideo = document.getElementById("remoteVideo");
    if (remoteVideo) {
      // Arr√™ter l'ancien flux s'il existe
      if (remoteVideo.srcObject) {
        const oldStream = remoteVideo.srcObject;
        if (oldStream && oldStream.getTracks) {
          oldStream.getTracks().forEach((track) => track.stop());
        }
      }

      // Attacher le nouveau flux avec un d√©lai pour √©viter les interruptions
      setTimeout(() => {
        // Attacher le nouveau flux
        remoteVideo.srcObject = stream;

        // Forcer la lecture avec retry
        const playVideo = async () => {
          try {
            // Forcer le volume √† un niveau audible
            remoteVideo.volume = 1.0;
            remoteVideo.muted = false;

            // Attendre un court instant avant de lancer la lecture
            await new Promise((resolve) => setTimeout(resolve, 100));

            // Forcer la lecture
            const playPromise = remoteVideo.play();

            if (playPromise !== undefined) {
              playPromise
                .then(() => {
                  // V√©rifier si la vid√©o joue r√©ellement
                  setTimeout(() => {
                    if (remoteVideo.paused) {
                      console.warn(
                        "La vid√©o est en pause malgr√© le succ√®s de play()"
                      );
                      remoteVideo
                        .play()
                        .catch((e) =>
                          console.error("Nouvelle tentative √©chou√©e:", e)
                        );
                    } else {
                    }
                  }, 1000);
                })
                .catch((error) => {
                  console.error(
                    "Erreur lors de la lecture automatique:",
                    error
                  );
                  // Si l'erreur est li√©e ÔøΩÔøΩ l'interaction utilisateur, afficher un message
                  if (error.name === "NotAllowedError") {
                    console.warn(
                      "La lecture automatique a √©t√© bloqu√©e. Interaction utilisateur requise."
                    );
                    // Afficher un bouton pour que l'utilisateur d√©marre la lecture
                    showPlayButton.value = true;
                  } else {
                    // Pour les autres erreurs, r√©essayer apr√®s un d√©lai
                    setTimeout(playVideo, 1000);
                  }
                });
            }
          } catch (error) {
            console.error("Erreur lors de la tentative de lecture:", error);
            setTimeout(playVideo, 1000);
          }
        };

        // Essayer de lire apr√®s un court d√©lai
        setTimeout(playVideo, 200);

        // √âgalement configurer l'√©v√©nement onloadedmetadata
        remoteVideo.onloadedmetadata = () => {
          setTimeout(playVideo, 100);
        };
      }, 200);

      return true;
    } else {
      console.warn("L'√©l√©ment vid√©o distant n'est pas trouv√© par ID");
      return false;
    }
  };

  // Essayer d'attacher imm√©diatement
  if (!attachStreamToVideo()) {
    // Si l'√©l√©ment n'est pas encore disponible, r√©essayer avec un d√©lai
    let attempts = 0;
    const maxAttempts = 10;
    const checkInterval = setInterval(() => {
      attempts++;
      if (attachStreamToVideo() || attempts >= maxAttempts) {
        clearInterval(checkInterval);
        if (attempts >= maxAttempts) {
          console.error(
            "Impossible de trouver l'√©l√©ment vid√©o distant apr√®s plusieurs tentatives"
          );
        }
      }
    }, 200); // V√©rifier toutes les 200ms
  }
};

/**
 * g√®re les changements de statut de l'appel.
 * met √† jour l'√©tat local du statut de l'appel et √©met un √©v√©nement pour notifier
 * les autres composants du changement.
 * @param {string} status - Le nouveau statut de l'appel (ex. 'en cours', 'termin√©', etc.).
 * @param {string} userId - L'identifiant de l'utilisateur concern√© par le changement de statut.
 * @param {boolean} withVideo - Indique si l'appel est vid√©o ou audio.
 */
const handleCallStatusChange = (status, userId, withVideo) => {
  // D√©marrer le timer quand l'appel est connect√©
  if (status === "connected") {
    // S'assurer qu'il n'y a pas d√©j√† un timer en cours
    if (timerInterval.value) {
      clearInterval(timerInterval.value);
    }

    callStartTime.value = Date.now();
    timerInterval.value = setInterval(() => {
      callDuration.value = Math.floor(
        (Date.now() - callStartTime.value) / 1000
      );
    }, 1000);
  } else if (status === "ended" || status === "rejected") {
    // Arr√™ter le timer si l'appel est termin√© ou rejet√©
    if (timerInterval.value) {
      clearInterval(timerInterval.value);
      timerInterval.value = null;
    }
    callDuration.value = 0;
    callStartTime.value = null;
  }

  emit("call-status-change", status, userId, withVideo);
};

 // √âcouteur pour la r√©ponse de permission d'enregistrement (c√¥t√© Agent)
 props.socket.on('record-permission-response', ({ from, to, granted }) => {
    if (props.userRole === 'agent' && to === props.currentUserId && from === props.remoteUserId) {
      awaitingRecordPermission.value = false;
      if (granted) {
        if (WebRTCService.startRecording()) {
          isRecording.value = true;
          props.socket.emit('recording-status-changed', { to: props.remoteUserId, recording: true });
          toast.success("Enregistrement d√©marr√© avec l'accord du client.");
        } else {
          isRecording.value = false;
          toast.error("Erreur lors du d√©marrage de l'enregistrement.");
        }
      } else {
        isRecording.value = false;
        toast.info("Le client a refus√© la demande d'enregistrement.");
      }
    }
  });

  // √âcouteur pour savoir si l'appel est en cours d'enregistrement (c√¥t√© Client)
  props.socket.on('recording-status-changed', ({ recording }) => {
    if (props.userRole === 'client') {
      isCallBeingRecordedByAgent.value = recording;
      // Vous pouvez utiliser isCallBeingRecordedByAgent.value pour afficher un indicateur au client
      if (recording) {
        toast.info("Cet appel est en cours d'enregistrement.", { timeout: 5000 });
      } else {
        toast.info("L'enregistrement de l'appel est termin√©.", { timeout: 3000 });
      }
    }
  });
  
watch(() => props.callStatus, async (newStatus) => {
  currentCallStatus.value = newStatus;

  if (newStatus === 'connected' && !localStream.value && props.initialLocalStream) {
          localStream.value = props.initialLocalStream;
     }

}, { immediate: true });

const auto_record_video_call = localStorage.getItem('auto_record_video_call');

/**
 *  fonction  appel√©e lorsque le composant est mont√©.
 *  initialise le service WebRTC et d√©marre l'appel sortant si n√©cessaire.
 */
onMounted(async () => {
  if (auto_record_video_call) {
    const maDonnee = JSON.parse(auto_record_video_call);
    console.log("Donn√©e r√©cup√©r√©e de l'autre projet :", maDonnee);
    // Tu peux maintenant utiliser maDonnee.utilisateur, maDonnee.theme, etc.
  } else {
    console.log("Aucune donn√©e partag√©e trouv√©e.");
  }
  // Initialiser le service WebRTC avec les param√®tres n√©cessaires
  WebRTCService.init(
    props.socket,
    props.currentUserId,
    (remote) => {
      if (!remote) {
        console.error("Received null remote stream");
        return;
      }
      remoteStream.value = remote;
      handleRemoteStream(remote);
    },
    handleCallStatusChange
  );
  
  watch(
    remoteStream,
    (newStream, oldStream) => {
      // Clean up old stream
      if (oldStream) {
        oldStream.getTracks().forEach((track) => track.stop());
      }

      if (newStream) {
        if (newStream.getVideoTracks().length === 0) {
          toast.warning("Aucune piste vid√©o dans le flux distant");
        }
      }
    },
    { immediate: true }
  );

  // Initialiser PeerJS
  try {
    await initPeerJS();
  } catch (error) {
    console.error(
      "Erreur lors de l'initialisation de PeerJS au montage:",
      error
    );
  }

  // √âcouter l'√©v√©nement screen-share-started
  props.socket.on("screen-share-started", (data) => {
    if (data.from === props.remoteUserId) {
      toast.info(`${props.remoteUserId} a commenc√© √† partager son √©cran`);
    }
  });

  // √âcouter l'√©v√©nement screen-share-stopped
  props.socket.on("screen-share-stopped", (data) => {
    if (data.from === props.remoteUserId) {
      toast.info(`${props.remoteUserId} a arr√™t√© de partager son √©cran`);
    }
  });

  // √âcouter l'√©v√©nement toggle-video
  props.socket.on("toggle-video", (data) => {
    if (data.from === props.remoteUserId) {
      // Mettre √† jour l'√©tat de la vid√©o distante
      remoteVideoEnabled.value = !data.off;
    }
  });

  // √âcouter l'√©v√©nement toggle-audio
  props.socket.on("toggle-audio", (data) => {
    if (data.from === props.remoteUserId) {
      // Mettre √† jour l'√©tat de la vid√©o distante
      remoteAudioEnabled.value = !data.off;
    }
  });

  // Si l'appel est sortant, d√©marrer l'appel
  if (props.callStatus === "outgoing" && props.remoteUserId) {
    startOutgoingCall();
  }
});

/**
 *  fonction  appel√©e lorsque le composant est d√©mont√©.
 *  termine l'appel WebRTC en cours pour lib√©rer les ressources.
 */
onUnmounted(() => {
  if (timerInterval.value) {
    clearInterval(timerInterval.value);
  }
  WebRTCService.endCall(); // Terminer l'appel en cours
  cleanupCallState();
});

/**
 *  surveille les changements des √©l√©ments vid√©o et des flux associ√©s.
 * Si un flux est disponible, il est attach√© √† l'√©l√©ment vid√©o correspondant.
 */
watch([localVideo, remoteVideo, localStream, remoteStream], () => {
  // Si l'√©l√©ment vid√©o local et le flux local sont disponibles, les attacher
  if (localVideo.value && localStream.value) {
    localVideo.value.srcObject = localStream.value;
  }
  // Si l'√©l√©ment vid√©o distant et le flux distant sont disponibles, les attacher
  if (remoteVideo.value && remoteStream.value) {
    remoteVideo.value.srcObject = remoteStream.value;
    remoteVideo.value.onloadedmetadata = async () => {
      try {
        await remoteVideo.value.play();
      } catch (error) {
        console.warn("Failed to play remote video in watch:", error);
      }
    };
  }
});

const isScreenSharer = ref(false);

const initPeerJS = async () => {
  try {
    return new Promise((resolve, reject) => {
      peerConnection.value = new Peer(props.currentUserId, {
        debug: 2,
        config: {
          iceServers: [
            { urls: "stun:stun.l.google.com:19302" },
            { urls: "stun:stun1.l.google.com:19302" },
            {
              urls: "turn:numb.viagenie.ca",
              username: "webrtc@live.com",
              credential: "muazkh",
            },
            {
              urls: "turn:openrelay.metered.ca:80",
              username: "openrelayproject",
              credential: "openrelayproject",
            },
          ],
        },
      });

      peerConnection.value.on("open", () => {
        resolve();
      });
      peerConnection.value.on("call", (call) => {
        // R√©pondre automatiquement √† l'appel de partage d'√©cran
        call.answer();
        // G√©rer le flux entrant
        call.on("stream", async (incomingStream) => {

          // Activer l'affichage et attendre que l'√©l√©ment soit cr√©√©
          screenSharingActive.value = true;

          // Attendre que l'√©l√©ment soit cr√©√© avec un d√©lai maximum
          let attempts = 0;
          const maxAttempts = 10;

          while (!screenShareVideo.value && attempts < maxAttempts) {
            await new Promise((resolve) => setTimeout(resolve, 100));
            attempts++;
          }

          if (!screenShareVideo.value) {
            console.error(
              "√âl√©ment vid√©o non trouv√© apr√®s plusieurs tentatives"
            );
            return;
          }

          // Arr√™ter l'ancien flux s'il existe
          if (screenShareVideo.value.srcObject) {
            screenShareVideo.value.srcObject
              .getTracks()
              .forEach((track) => track.stop());
          }

          // Attacher le nouveau flux
          screenShareVideo.value.srcObject = incomingStream;

          // Forcer la lecture avec retry
          const playVideo = async () => {
            try {
              await screenShareVideo.value.play();
            } catch (error) {
              console.error("Erreur lors de la lecture:", error);
              setTimeout(playVideo, 1000);
            }
          };

          screenShareVideo.value.onloadedmetadata = () => {
            playVideo();
          };
        });
        call.on("error", (error) => {
          console.error("Erreur sur l'appel de partage d'√©cran:", error);
        });
      });

      peerConnection.value.on("error", (err) => {
        console.error("Erreur PeerJS:", err);
        reject(err);
      });

      // Gestion des connexions entrantes
      peerConnection.value.on("connection", (conn) => {
        remotePeerConnection.value = conn;

        conn.on("data", (data) => {
          if (data.type === "screen-share-stopped") {
            toast.info(`${props.remoteUserId} a arr√™t√© de partager son √©cran`);
          }
        });
      });
    });
  } catch (error) {
    console.error("√âchec de l'initialisation de PeerJS:", error);
    throw error;
  }
};

const startScreenShare = async () => {
  try {
    if (!peerConnection.value) {
      console.error("PeerJS not initialized");
      toast.error("Erreur d'initialisation pour le partage d'√©cran");
      await initPeerJS();
    }

    // Get screen sharing stream
    const screenStream = await navigator.mediaDevices.getDisplayMedia({
      video: true,
      audio: false,
    });
    // Afficher le flux de partage d'√©cran dans le nouvel √©l√©ment vid√©o
    if (screenShareVideo.value) {
      screenShareVideo.value.srcObject = screenStream;
    }

    // Connect to remote peer if not already connected
    if (!remotePeerConnection.value) {
      remotePeerConnection.value = peerConnection.value.connect(
        props.remoteUserId
      );

      // Wait for connection to open
      remotePeerConnection.value.on("open", () => {
        sendScreenStream(screenStream);
      });
    } else {
      sendScreenStream(screenStream);
    }

    // Handle stream ending
    screenStream.getVideoTracks()[0].onended = () => {
      stopScreenShare();
    };

    isScreenSharer.value = true;
    screenSharingActive.value = true;

    // Notify via socket
    props.socket.emit("screen-share-started", {
      from: props.currentUserId,
      to: props.remoteUserId,
    });

    toast.success("Partage d'√©cran d√©marr√©");
  } catch (error) {
    console.error("Erreur lors du partage d'√©cran:", error);
    toast.error("Impossible de partager l'√©cran. Veuillez r√©essayer.");
  }
};

const screenShareCall = ref(null);

const stopScreenShare = async () => {
  try {
    // Arr√™ter le partage d'√©cran
    if (screenShareVideo.value && screenShareVideo.value.srcObject) {
      screenShareVideo.value.srcObject
        .getTracks()
        .forEach((track) => track.stop());
      screenShareVideo.value.srcObject = null;
    }

    // Fermer l'appel de partage d'√©cran
    if (screenShareCall.value) {
      screenShareCall.value.close();
      screenShareCall.value = null;
    }
    isScreenSharer.value = false;
    screenSharingActive.value = false;

    await nextTick();

    // Notify remote peer
    if (remotePeerConnection.value && remotePeerConnection.value.open) {
      remotePeerConnection.value.send({
        type: "screen-share-stopped",
        from: props.currentUserId,
      });
    }

    // Notify via socket
    props.socket.emit("screen-share-stopped", {
      from: props.currentUserId,
      to: props.remoteUserId,
    });
    screenSharingActive.value = false;
    isScreenSharer.value = null;
    toast.info("Partage d'√©cran arr√™t√©");
  } catch (error) {
    console.error("Erreur lors de l'arr√™t du partage d'√©cran:", error);
    toast.error("Erreur lors de l'arr√™t du partage d'√©cran");
  }
};

const sendScreenStream = (screenStream) => {
  try {
    if (!props.remoteUserId) {
      throw new Error("ID du pair distant non d√©fini");
    }

    // Cr√©er l'appel avec le flux d'√©cran
    const call = peerConnection.value.call(props.remoteUserId, screenStream, {
      metadata: { type: "screen-share" },
      sdpTransform: (sdp) => {
        // Forcer une meilleure qualit√© vid√©o
        return sdp.replace(
          "useinbandfec=1",
          "useinbandfec=1;stereo=1;maxaveragebitrate=510000"
        );
      },
    });

    call.on("error", (err) => {
      console.error("Erreur lors de l'appel de partage d'√©cran:", err);
      toast.error("Erreur lors du partage d'√©cran");
    });

    call.on("stream", (remoteStream) => {
    });

    // Sauvegarder l'appel pour pouvoir le fermer plus tard
    screenShareCall.value = call;

    // Notification via data connection
    if (remotePeerConnection.value && remotePeerConnection.value.open) {
      remotePeerConnection.value.send({
        type: "screen-share-started",
        from: props.currentUserId,
      });
    }
  } catch (error) {
    console.error("Erreur lors de l'envoi du flux de partage d'√©cran:", error);
    toast.error("Erreur lors du partage d'√©cran");
  }
};

/**
 *  tente d'obtenir le m√©dia local (audio et/ou vid√©o) et de d√©marrer l'appel une fois la configuration termin√©e.
 */
const acceptCall = async () => {
  try {
    // Obtenir le flux local
    const result = await WebRTCService.getLocalMedia(localIsVideoCall.value);
    if (!result.success) {
      throw result.error;
    }

    // Sauvegarder et afficher le flux local
    localStream.value = result.stream;
    if (localVideo.value) {
      localVideo.value.srcObject = result.stream;
    }

    // Accepter l'appel et envoyer notre flux local
    await WebRTCService.acceptCall(result.stream);

    // Mettre √† jour le statut
    currentCallStatus.value = "connected";
    emit(
      "call-status-change",
      "connected",
      props.remoteUserId,
      localIsVideoCall.value
    );

    // Configurer la gestion du flux distant
    WebRTCService.onRemoteStream((remoteStream) => {
      if (remoteVideo.value) {
        remoteVideo.value.srcObject = remoteStream;
        remoteStream.value = remoteStream;
      }
    });
  } catch (error) {
    console.error("Failed to accept call:", error);
    emit("call-ended");
  }
};

// fonction pour nettoyer les √©tats
const cleanupCallState = () => {
  // Arr√™ter le chronom√®tre d'abord
  if (timerInterval.value) {
    clearInterval(timerInterval.value);
    timerInterval.value = null;
  }

  // R√©initialiser les flux
  if (localStream.value) {
    localStream.value.getTracks().forEach((track) => track.stop());
    localStream.value = null;
  }
  if (remoteStream.value) {
    remoteStream.value.getTracks().forEach((track) => track.stop());
    remoteStream.value = null;
  }

  // R√©initialiser les √©l√©ments vid√©o
  if (localVideo.value) localVideo.value.srcObject = null;
  if (remoteVideo.value) remoteVideo.value.srcObject = null;

  // R√©initialiser les √©tats
  currentCallStatus.value = "";
  isMuted.value = false;
  isVideoOff.value = false;
  callDuration.value = 0;
  callStartTime.value = null;
};

/**
 *  met fin √† l'appel en rejetant la connexion via WebRTC et notifie les autres composants.
 */
const rejectCall = () => {
  // Rejeter l'appel via WebRTC
  WebRTCService.rejectCall();
  // Nettoyer les √©tats
  cleanupCallState();
  // √âmettre un √©v√©nement pour indiquer que l'appel est termin√©
  emit("call-ended");
};

/**
 *  termine l'appel via WebRTC et notifie les autres composants.
 */
const endCall = () => {
  // Terminer l'appel via WebRTC
  WebRTCService.endCall();
  // Nettoyer les √©tats
  cleanupCallState();
  // √âmettre un √©v√©nement pour indiquer que l'appel est termin√©
  emit("call-ended");
};

onUnmounted(() => {
  if (WebRTCService.onMediaStateChange) {
    WebRTCService.onMediaStateChange = null;
  }
  if (peerConnection.value) {
    peerConnection.value.destroy();
    peerConnection.value = null;
  }
});

/**
 *  bascule l'√©tat de l'audio et notifie le service WebRTC.
 */
const toggleMute = () => {
  isMuted.value = !isMuted.value;
  WebRTCService.toggleAudio(
    isMuted.value,
    props.remoteUserId,
    props.currentUserId
  );
};

const remoteVideoEnabled = ref(true);
const remoteAudioEnabled = ref(true);
/**
 *  bascule l'√©tat de la vid√©o et notifie le service WebRTC.
 */
const toggleVideo = () => {
  isVideoOff.value = !isVideoOff.value;
  WebRTCService.toggleVideo(
    isVideoOff.value,
    props.remoteUserId,
    props.currentUserId
  );
};
</script>

<style scoped>
.play-video-button {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  background-color: rgba(0, 0, 0, 0.7);
  color: white;
  border: none;
  border-radius: 50%;
  width: 80px;
  height: 80px;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  cursor: pointer;
  z-index: 10;
  padding: 20px;
  font-size: 12px;
  transition: all 0.3s ease;
}

.play-video-button:hover {
  background-color: rgba(0, 0, 0, 0.9);
  transform: translate(-50%, -50%) scale(1.1);
}

.play-video-button svg {
  margin-bottom: 5px;
}

.play-video-button span {
  font-size: 10px;
  text-align: center;
  max-width: 100px;
}
.call-container {
  position: relative;
  width: 100%;
  height: 100%;
  background-color: #1a1a1a;
  color: white;
  display: flex;
  flex-direction: column;
  overflow: hidden;
}

.screen-share-video {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  width: 80%;
  height: 80%;
  object-fit: contain;
  border-radius: 12px;
  /* z-index: 100; */
}

.remote-stream-container {
  flex: 1;
  display: flex;
  justify-content: center;
  align-items: center;
  overflow: hidden;
}

.remote-stream-container video {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.local-stream-container {
  position: absolute;
  bottom: 80px;
  right: 20px;
  width: 150px;
  height: 200px;
  border-radius: 8px;
  overflow: hidden;
  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
  border: 2px solid white;
}

.local-stream-container video {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.call-controls {
  position: absolute;
  bottom: 20px;
  left: 0;
  right: 0;
  display: flex;
  justify-content: center;
  gap: 20px;
  padding: 10px;
}

.control-btn {
  width: 50px;
  height: 50px;
  border-radius: 50%;
  background-color: rgba(255, 255, 255, 0.2);
  border: none;
  display: flex;
  justify-content: center;
  align-items: center;
  color: white;
  cursor: pointer;
  transition: all 0.3s ease;
}

.control-btn:hover {
  background-color: rgba(255, 255, 255, 0.3);
}

.control-btn.active {
  background-color: #dc2626;
}

.control-btn.end-call {
  background-color: #dc2626;
}

.recording {
  background-color: rgba(255, 0, 0, 0.2);
}

.control-button {
  position: relative;
}

.control-button.recording::after {
  content: "";
  position: absolute;
  top: 4px;
  right: 4px;
  width: 8px;
  height: 8px;
  background-color: #ff0000;
  border-radius: 50%;
  animation: pulse 1.5s infinite;
}

@keyframes pulse {
  0% {
    transform: scale(1);
    opacity: 1;
  }

  50% {
    transform: scale(1.5);
    opacity: 0.5;
  }

  100% {
    transform: scale(1);
    opacity: 1;
  }
}

.local-audio-indicator {
  width: 100%;
  height: 100%;
  display: flex;
  justify-content: center;
  align-items: center;
  background-color: #1a1a1a;
}

.local-stream-container .user-avatar span {
  font-size: 1.5rem;
  width: 3rem;
  height: 3rem;
}

.background-initial {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 0;
  opacity: 0.1;
  pointer-events: none;
}

.large-initial {
  font-size: 25rem;
  font-weight: bold;
  color: white;
}

.call-timer {
  position: absolute;
  top: 20px;
  left: 50%;
  transform: translateX(-50%);
  background-color: rgba(0, 0, 0, 0.5);
  padding: 5px 15px;
  border-radius: 15px;
  font-size: 1.2rem;
  font-weight: bold;
}
.call-status {
  position: absolute;
  top: 20px;
  left: 50%;
  transform: translateX(-50%);
  z-index: 10;
}

.status-message {
  color: white;
  padding: 6px 12px;
  border-radius: 8px;
  font-size: 1.2rem;
}
</style>
